{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDF Connect Client Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdf_connect_client import MDFConnectClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Overview/instantiation](#MDF-Connect-Client)\n",
    "- [Mandatory inputs](#Mandatory-inputs)\n",
    "- [Recommended inputs](#Recommended-inputs)\n",
    "- [Optional inputs](#Optional-inputs)\n",
    "- [Submitting a dataset](#Submitting-a-dataset)\n",
    "- [Checking submission status](#Checking-submission-status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDF Connect Client\n",
    "The MDF Connect Client (`MDFConnectClient`) is a class designed to help you submit datasets to MDF Connect using Python. When you instantiate the Client, it will attempt to authenticate you with Globus automatically. You cannot use MDF Connect anonymously.\n",
    "\n",
    "Note: While you can access and modify the internal variables of a client (for example, `mdfcc.data`), it is recommended that you instead only use the helper functions. This tutorial accesses those variables only for display purposes.\n",
    "\n",
    "**IMPORTANT**: To submit data to MDF Connect, you must have an account recognized by Globus Auth (including Google, ORCiD, many academic institutions, or a [free Globus ID](https://www.globusid.org/create)). Additionally, you must be in the [MDF Connect Convert](https://www.globus.org/app/groups/cc192dca-3751-11e8-90c1-0a7c735d220a/about) Globus Group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDFCC Constructor (`MDFConnectClient`)\n",
    "It is recommended that you use the helper functions (detailed below) to construct your MDF Connect submission. However, if you have already assembled all or part of your submission, you can pre-load your client with the appropriate metadata.\n",
    "\n",
    "#### Recommended arguments:\n",
    "- `test` (boolean): When `True`, enables test mode. When `False`, disables test mode. For more information about test mode, see `set_test()`.\n",
    "\n",
    "#### Optional arguments (if you have already prepared metadata):\n",
    "- `dc` (dictionary): The DataCite block.\n",
    "- `mdf` (dictionary): The MDF block.\n",
    "- `mrr` (dictionary): The MRR block.\n",
    "- `custom` (dictionary): The `__custom` block.\n",
    "- `data` (list): The list of data locations.\n",
    "- `index` (dictionary): The special indexing instructions.\n",
    "- `services` (dictionary): The requested service integrations.\n",
    "\n",
    "Note: If you have the entire submission already prepared, you can skip to [Submitting a dataset](#Submitting-a-dataset) and pass your submission directly to `submit_dataset()`.\n",
    "\n",
    "#### Advanced optional arguments (developer use only):\n",
    "- `service_instance` (string): The instance of the MDF Connect service to use. Normal users should not alter this value.\n",
    "- `authorizer` (Authorizer): A valid, authenticated Authorizer from the Globus SDK. Normal users do not need to change this value. Accepted Authorizers are:\n",
    "    - globus_sdk.RefreshTokenAuthorizer\n",
    "    - globus_sdk.ClientCredentialsAuthorizer\n",
    "    - globus_sdk.NullAuthorizer (This Authorizer will fail authentication.)\n",
    "\n",
    "The advanced arguments may cause issues, and are not recommended for normal users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfcc = MDFConnectClient(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory inputs\n",
    "\n",
    "- [`create_dc_block`](#create_dc_block)\n",
    "- [`add_data`](#add_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_dc_block`\n",
    "The `dc` (DataCite) block is mandatory for all submissions. `create_dc_block()` helps create the `dc` block for you.\n",
    "\n",
    "#### Required arguments:\n",
    "- `title` (string): The title of the dataset.\n",
    "- `authors` (string or list of strings): The authors of the dataset, in one of these forms:\n",
    "    - \"Givenname Familyname\"\n",
    "    - \"Familyname, Givenname\"\n",
    "    - \"Familyname; Givenname\"\n",
    "\n",
    "#### Arguments with defaults:\n",
    "- `publisher` (string): The publisher of this dataset (*not* an associated paper). The default is \"Materials Data Facility\".\n",
    "- `publication_year` (integer or string): The year the dataset was published. The default is the current year.\n",
    "- `resource_type` (string): The type of resource. Except in unusual cases, this should be \"Dataset\". The default is \"Dataset\". Unless you know that your submission needs a different value, please leave it as the default.\n",
    "\n",
    "#### Optional arguments (not present by default):\n",
    "- `affiliations` (string or list of strings): The affiliations of the authors, in the same order as the authors. If a different number of affiliations are given, all affiliations will be applied to all authors. Multiple author affiliations can be given as a list. (See examples below for more details.)\n",
    "- `description` (string): A description of the dataset.\n",
    "- `dataset_doi` (string): The DOI for this dataset (*not* an associated paper).\n",
    "- `related_dois` (string or list of strings): DOIs related to this dataset, such as an associated paper's DOI. This *does not* include a DOI for the dataset itself. \n",
    "- `subjects` (string or list of strings): Subjects (in Datacite terminology) or tags related to the dataset.\n",
    "\n",
    "\n",
    "If you understand the DataCite schema, you can also add other keyword arguments corresponding to DataCite fields. Additional information on DataCite fields is available from the [official DataCite website](https://schema.datacite.org/meta/kernel-4.1/).\n",
    "\n",
    "You cannot clear the `dc` block. You can overwrite the `dc` block by calling this method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra affiliations examples\n",
    "# Assume we have three authors: Alice, Bob, and Cathy\n",
    "authors = [\"Fromnist, Alice\", \"Fromnist; Bob\", \"Cathy Multiples\"]\n",
    "\n",
    "# If all authors are from NIST:\n",
    "affiliations = \"NIST\"\n",
    "# Equivalent to [\"NIST\", \"NIST\", \"NIST\"]\n",
    "\n",
    "# If all authors are from both NIST and UChicago:\n",
    "affiliations = [\"NIST\", \"UChicago\"]\n",
    "# Equivalent to [[\"NIST\", \"UChicago\"], [\"NIST\", \"UChicago\"], [\"NIST\", \"UChicago\"]]\n",
    "\n",
    "# If Alice and Bob are from NIST, Cathy is from NIST and UChicago:\n",
    "affliliations = [\"NIST\", \"NIST\", [\"NIST\", \"UChicago\"]]\n",
    "# This is the only way to express these affiliations\n",
    "\n",
    "# This is incorrect! If applying affiliations to all authors, lists must not be nested.\n",
    "# These apply to all authors because there are 4 affiliations for 3 authors.\n",
    "affiliations = [\"NIST\", [\"NIST\", \"UChicago\"], \"Argonne\", \"Oak Ridge\"]\n",
    "# Do not use this format, it is incorrect for this number of authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creators': [{'affiliations': ['The International Institute of Data'],\n",
       "   'creatorName': 'Smith, Foo',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Foo'},\n",
       "  {'affiliations': ['The International Institute of Data'],\n",
       "   'creatorName': 'Smith, Bar',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Bar'},\n",
       "  {'affiliations': ['The International Institute of Data'],\n",
       "   'creatorName': 'Smith, Baz',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Baz'}],\n",
       " 'descriptions': [{'description': 'This is an example submission.',\n",
       "   'descriptionType': 'Other'}],\n",
       " 'identifier': {'identifier': '10.1234/dataset', 'identifierType': 'DOI'},\n",
       " 'publicationYear': '2000',\n",
       " 'publisher': 'The Journal of Datasets',\n",
       " 'relatedIdentifiers': [{'relatedIdentifier': '10.1234/paper1',\n",
       "   'relatedIdentifierType': 'DOI',\n",
       "   'relationType': 'IsPartOf'},\n",
       "  {'relatedIdentifier': '10.1234/paper2',\n",
       "   'relatedIdentifierType': 'DOI',\n",
       "   'relationType': 'IsPartOf'}],\n",
       " 'resourceType': {'resourceType': 'Dataset', 'resourceTypeGeneral': 'Dataset'},\n",
       " 'subjects': [{'subject': 'Examples'}, {'subject': 'Datasets'}],\n",
       " 'titles': [{'title': 'Example of Dataset Submission'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_dc_block(title=\"Example of Dataset Submission\",\n",
    "                      authors=[\"Foo Smith\", \"Smith, Bar\", \"Smith; Baz\"],\n",
    "                      affiliations=[\"The International Institute of Data\"],\n",
    "                      publisher=\"The Journal of Datasets\",\n",
    "                      publication_year=2000,\n",
    "                      description=\"This is an example submission.\",\n",
    "                      dataset_doi=\"10.1234/dataset\",\n",
    "                      related_dois=[\"10.1234/paper1\", \"10.1234/paper2\"],\n",
    "                      subjects=[\"Examples\", \"Datasets\"])\n",
    "mdfcc.dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creators': [{'affiliations': ['Foo University'],\n",
       "   'creatorName': 'Smith, Foo',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Foo'},\n",
       "  {'affiliations': ['The Bureau of Bar'],\n",
       "   'creatorName': 'Smith, Bar',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Bar'}],\n",
       " 'publicationYear': '2018',\n",
       " 'publisher': 'Materials Data Facility',\n",
       " 'resourceType': {'resourceType': 'Dataset', 'resourceTypeGeneral': 'Dataset'},\n",
       " 'titles': [{'title': 'Smaller Example Dataset Submission'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_dc_block(title=\"Smaller Example Dataset Submission\",\n",
    "                      authors=[\"Foo Smith\", \"Smith, Bar\"],\n",
    "                      affiliations=[\"Foo University\", \"The Bureau of Bar\"])\n",
    "\n",
    "mdfcc.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_data`\n",
    "Some kind of data is mandatory for all submissions. `add_data()` will add a data location to your dataset. This action is cumulative, so each calls adds more data. Subsequent calls do not overwrite.\n",
    "\n",
    "#### Required arguments:\n",
    "- `data_location` (string): The location of the data.\n",
    "\n",
    "You can add data located at a Globus endpoint, HTTP(S) link, or on Google Drive. MDF Connect will extract data located in archives, including zips.\n",
    "\n",
    "- Globus endpoint: `globus://endpoint_id/path/to/data` or you can copy the \"Get link\" link from the Globus Web App. The data must be shared with `mdf_dataset_submission`, which is the MDF Connect Globus account. (This account will show up as `c17f27bb-f200-486a-b785-2a25e82af505@clients.auth.globus.org`.)\n",
    "- HTTP(S): Copy the link exactly. The data must be accessible without authentication.\n",
    "- Google Drive: `googledrive:///path/from/shared/location`. You must share the data with materialsdatafacility@gmail.com.\n",
    "\n",
    "To clear all data from the submission, call `clear_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dl.dropboxusercontent.com/u/12345/abcdef',\n",
       " 'googledrive:///mydata.zip',\n",
       " 'globus://1a2b3c/data/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_data(\"https://dl.dropboxusercontent.com/u/12345/abcdef\")\n",
    "mdfcc.add_data([\"googledrive:///mydata.zip\", \"globus://1a2b3c/data/\"])\n",
    "mdfcc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_data()\n",
    "mdfcc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.globus.org/app/transfer?origin_id=e38ee745-6d04-11e5-ba46-22000b92c6ec&origin_path=%2Fcitrine_mdf_demo%2Falloy.pbe%2FAlFe%2F']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the actual test data, using a Globus Web App link\n",
    "mdfcc.add_data(\"https://www.globus.org/app/transfer?origin_id=e38ee745-6d04-11e5-ba46-22000b92c6ec&origin_path=%2Fcitrine_mdf_demo%2Falloy.pbe%2FAlFe%2F\")\n",
    "mdfcc.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended inputs\n",
    "\n",
    "- [`add_index`](#add_index)\n",
    "- [`add_service`](#add_service)\n",
    "- [`set_test`](#set_test)\n",
    "- [`add_repositories`](#add_repositories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_index`\n",
    "To process JSON, CSV, YAML, XML, or Excel files, MDF Connect requires a mapping that translates the file into MDF schema format. `add_index()` will add a mapping for a specific data type to your submission.\n",
    "\n",
    "#### Required arguments:\n",
    "- `data_type` (string): The type of data being mapped. Supported types include:\n",
    "    - `json`\n",
    "    - `csv`\n",
    "    - `yaml`\n",
    "    - `xml`\n",
    "    - `excel`\n",
    "    - `filename` (This type is special; see below.)\n",
    "- `mapping` (dictionary of strings): The mapping of MDF fields to your data type's fields (see below).\n",
    "\n",
    "#### Arguments with defaults:\n",
    "- `delimiter` (string): For tabular data (ex. CSV), the column delimiter. The default is \",\" (comma).\n",
    "- `na_values` (string or list of strings): Values to treat as \"data missing\" entries. The default for tabular data (ex. CSV), v is blank and space, while the default for other types (ex. JSON) is nothing (no values will be discarded).\n",
    "\n",
    "#### About `mapping`:\n",
    "Mappings must be dictionaries, where the key is the MDF schema field (expressed in dot notation) and the value is the data's field or column name. \"Dot notation\" means one string that uses a period between dictionary levels. For example, `block.field.subfield` is the dot notation equivalent of `my_dict[\"block\"][\"field\"][\"subfield\"]` in Python.\n",
    "The exception to this is `filename` mapping. To extract data from a file's name, create a regular expression that returns the correct information. The mapping field is still the associated MDF field in dot notation, but the mapping value is the regular expression you created.\n",
    "\n",
    "Fields with missing data will be ignored. If you have multiple schemas for one data type in one dataset, you can combine the mappings safely.\n",
    "\n",
    "Each data type can only have one associated mapping, so multiple calls with the same data type will overwrite. Calls with different data types will not overwrite. To clear all the mappings, call `clear_index()`.\n",
    "\n",
    "For more information on the MDF schemas, see the [official schema repository](https://github.com/materials-data-facility/data-schemas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example, assume we're submitting a dataset that contains a JSON file structured like this:\n",
    "```json\n",
    "{\n",
    "    \"my_data\": {\n",
    "        \"mat\": {\n",
    "            \"comp\": \"H\"\n",
    "        },\n",
    "        \"atom_num\": 1\n",
    "    },\n",
    "    \"space_grp\": 10\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the mapping we would use to get the JSON file into MDF format.\n",
    "mapping = {\n",
    "    \"material.composition\": \"my_data.mat.comp\",\n",
    "    \"crystal_structure.number_of_atoms\": \"my_data.atom_num\",\n",
    "    \"crystal_structure.space_group_number\": \"space_grp\",\n",
    "    # We could add another field here, if we had multiple JSON schemas.\n",
    "    \"dft.converged\": \"dft_info.conv\"\n",
    "    # This field would be ignored by MDF Connect in this submission because the field doesn't exist in the data.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'json': {'mapping': {'crystal_structure.number_of_atoms': 'my_data.atom_num',\n",
       "   'crystal_structure.space_group_number': 'space_grp',\n",
       "   'dft.converged': 'dft_info.conv',\n",
       "   'material.composition': 'my_data.mat.comp'}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_index(\"json\", mapping)\n",
    "mdfcc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_index()\n",
    "mdfcc.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_service`\n",
    "MDF Connect has integrations to submit data to other community services, as well as additional MDF-related options. To automatically submit your dataset to an integrated service, use `add_service()`.\n",
    "\n",
    "#### Required arguments:\n",
    "- `service` (string): One service to push your dataset to. Integrated services include:\n",
    "    - `globus_publish`, the Globus/MDF publication service with DOI minting\n",
    "    - `citrine`, industry-partnered machine-learning specialists\n",
    "    - `mrr`, the NIST Materials Resource Registry\n",
    "\n",
    "#### Arguments with defaults:\n",
    "- `parameters` (dictionary): Optional, service-specific parameters. Fields include:\n",
    "    - For `globus_publish`:\n",
    "        - `parameters` currently unavailable.\n",
    "    - For `citrine`:\n",
    "        - public (boolean): When `True`, the data will be made public. Otherwise, the data will be inaccessible. The default is `True`.\n",
    "\n",
    "This action is cumulative, so subsequent calls will add more services, not overwrite previous.\n",
    "\n",
    "To clear all the service selections from your submission, call `clear_services()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citrine': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_service(\"citrine\")\n",
    "mdfcc.services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_services()\n",
    "mdfcc.services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_test`\n",
    "You can use `set_test()` to create a test submission as a dry-run for MDF Connect. The submission will go through the normal processing, but the results will not be submitted to the normal locations. This flag is a great way to tell if your submission will process the way you want it to.\n",
    "\n",
    "#### Required arguments:\n",
    "- `test` (boolean): When `True`, enables test mode. When `False`, disables test mode.\n",
    "\n",
    "#### About test mode:\n",
    "Test datasets are submitted to test/sandbox/temporary resources instead of live resources, including the following. These setting override all other parameters.\n",
    "- Tests are ingested into the `mdf-test` search index\n",
    "- Tests are submitted to the MDF Test collection in Globus Publish (if `globus_publish` is a requested service)\n",
    "- Tests are not made public on Citrination (if `citrine` is a requested service)\n",
    "- Tests are given a special `source_id` by prepending `_test_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_test(False)\n",
    "mdfcc.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_test(True)\n",
    "mdfcc.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_repositories`\n",
    "`add_repositories()` adds repository tags to your submission. This action is cumulative, so each call adds more repositories. Subsequent calls do not overwrite.\n",
    "\n",
    "#### Required arguments:\n",
    "- `repositories` (string or list of strings): The repositories to add.\n",
    "\n",
    "Some repositories may be added automatically if implied by your supplied tags. Repositories that aren't recognized may be discarded.\n",
    "\n",
    "To clear your repository tags, call `clear_repositories()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repositories': ['APS', 'NREL']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_repositories([\"APS\", \"NREL\"])\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_repositories()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional inputs\n",
    "\n",
    "- [`set_custom_block`](#set_custom_block)\n",
    "- [`set_custom_descriptions`](#set_custom_descriptions)\n",
    "- [`set_acl`](#set_acl)\n",
    "- [`set_source_name`](#set_source_name)\n",
    "- [`create_mrr_block`](#create_mrr_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_custom_block`\n",
    "The `__custom` block is an area for you to add your own custom metadata, if it isn't covered by the MDF schema. It can be set by calling `set_custom_block()`.\n",
    "\n",
    "#### Required arguments:\n",
    "- `custom_fields` (dictionary): Custom field-value pairs for your dataset.\n",
    "\n",
    "You are allowed ten keys in your custom dictionary. You may additionally add descriptions of your fields by creating a new field called \"\\[field\\]\\_desc\" with the string description inside. You can also add descriptions by calling `set_custom_descriptions()`.\n",
    "\n",
    "Note that, unlike the `index` mappings, you supply the actual values for the dataset-level `__custom` block.\n",
    "\n",
    "Subsequent calls will overwrite your `__custom` block. You can clear the `__custom` block by passing in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quench_method': 'water', 'quench_method_desc': 'The method of quenching'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_values = {\n",
    "        \"quench_method\": \"water\",\n",
    "        \"quench_method_desc\": \"The method of quenching\"\n",
    "}\n",
    "mdfcc.set_custom_block(custom_values)\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_custom_block({})\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_custom_descriptions`\n",
    "To add descriptions for your `__custom` block fields, you can call `set_custom_descriptions()`.\n",
    "\n",
    "#### Required arguments:\n",
    "- `custom_descriptions` (dictionary): The custom fields and descriptions. The dictionary fields must be the same as your `__custom` block fields, and the values must be their descriptions.\n",
    "\n",
    "Every field in `__custom` can have a description, but descriptions are not allowed without a corresponding field.\n",
    "\n",
    "Subsequent calls will overwrite the descriptions you provide. To clear descriptions, you have to use `set_custom_block()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quench_method': 'water'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_values = {\n",
    "        \"quench_method\": \"water\"\n",
    "}\n",
    "mdfcc.set_custom_block(custom_values)\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quench_method': 'water', 'quench_method_desc': 'The method of quenching'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_desc = {\n",
    "        \"quench_method\": \"The method of quenching\"\n",
    "}\n",
    "mdfcc.set_custom_descriptions(custom_desc)\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_custom_block({})\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_acl`\n",
    "`set_acl()` sets the Access Control List for this submission.\n",
    "\n",
    "#### Required arguments:\n",
    "- acl (string or list of strings): The Access Control List. The ACL must contain either the Globus UUIDs of users and/or groups allowed to access the submission, or `\"public\"` to make the submission open to everyone. The default ACL is `\"public\"`.\n",
    "\n",
    "You can reset the ACL to the default with `clear_acl()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acl': ['UUID1', 'UUID2']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_acl([\"UUID1\", \"UUID2\"])\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_acl()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set_source_name`\n",
    "`set_source_name()` sets the `source_name` of your dataset. By default, the `source_name` is generated based on the title of your dataset (as set in the `dc` block). If your title is long or otherwise unwieldy to type or remember, setting a custom `source_name` can help.\n",
    "\n",
    "#### Required arguments:\n",
    "- `source_name` (string): The desired `source_name`, which must be unique for new datasets.\n",
    "\n",
    "Please note that your source name will be cleaned when submitted to MDF Connect, so the actual source_name may differ from this value. Additionally, the `source_id` (which is the `source_name` plus version) is required to fetch the status of a submission. `check_status()` can handle this for you.\n",
    "\n",
    "You can reset the `source_name` to the default by calling `clear_source_name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_name': 'my_foobar_dataset'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_source_name(\"my_foobar_dataset\")\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_source_name()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_mrr_block`\n",
    "`create_mrr_block()` adds data for the NIST Materials Resource Registry into your submission. Currently, you must build a dictionary with the appropriate fields yourself in order to attach MRR metadata.\n",
    "\n",
    "#### Required arguments:\n",
    "- `mrr_data` (dictionary): The Materials Resource Registry metadata.\n",
    "\n",
    "You can clear the `mrr` block by passing in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataOrigin': 'experiment'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_mrr_block({\"dataOrigin\": \"experiment\"})\n",
    "mdfcc.mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_mrr_block({})\n",
    "mdfcc.mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting a dataset\n",
    "After you have created your submission with the above helpers, you can submit and check your submission with the following helpers.\n",
    "\n",
    "- [`get_submission`](#get_submission)\n",
    "- [`reset_submission`](#reset_submission)\n",
    "- [`submit_dataset`](#submit_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_submission`\n",
    "`get_submission()` shows you your current submission, as it will be sent to MDF Connect. This method is a great way to check for any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': ['https://www.globus.org/app/transfer?origin_id=e38ee745-6d04-11e5-ba46-22000b92c6ec&origin_path=%2Fcitrine_mdf_demo%2Falloy.pbe%2FAlFe%2F'],\n",
       " 'dc': {'creators': [{'affiliations': ['Foo University'],\n",
       "    'creatorName': 'Smith, Foo',\n",
       "    'familyName': 'Smith',\n",
       "    'givenName': 'Foo'},\n",
       "   {'affiliations': ['The Bureau of Bar'],\n",
       "    'creatorName': 'Smith, Bar',\n",
       "    'familyName': 'Smith',\n",
       "    'givenName': 'Bar'}],\n",
       "  'publicationYear': '2018',\n",
       "  'publisher': 'Materials Data Facility',\n",
       "  'resourceType': {'resourceType': 'Dataset',\n",
       "   'resourceTypeGeneral': 'Dataset'},\n",
       "  'titles': [{'title': 'Smaller Example Dataset Submission'}]},\n",
       " 'test': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.get_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `reset_submission`\n",
    "If you need to clear away your entire submission, call `reset_submission()`. This is irreversible.\n",
    "\n",
    "Caution: This method will clear the current `source_id`, which means that you will have to keep track of any previous `source_id`s from other submissions to see their statuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdfcc.reset_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `submit_dataset`\n",
    "`submit_dataset()` will send your dataset to MDF Connect for indexing. You will get back the `source_id` if the submission is successful. The `source_id` is the unique identifier for your specific submission, and can be used to check the status of your submission later. The `source_id` is also saved to the client.\n",
    "\n",
    "#### Optional arguments:\n",
    "- `resubmit` (boolean): If you wish to submit this dataset after submitting it previously, set this to `True`. If this is the first submission, leave this `False`. The default is `False`.\n",
    "- `submission` (dictionary): If you have assembled your own MDF Connect submission without this client, you can submit it by passing the dictionary in here. By default, the submission made in the client will be used.\n",
    "- `reset` (boolean): If True, the submission will be cleared after the submission attempt, with `reset_submission()`. The test flag will be preserved. The default is `False`. Caution: This flag will clear your `source_id`, which means that you will have to keep track of it manually to check your submission's status.\n",
    "\n",
    "#### Return value:\n",
    "- A dictionary with the following submission information:\n",
    "    - `success` (boolean): `True` if the submission was successfully sent to MDF Connect. `False` otherwise.\n",
    "    - `source_id` (string): The `source_id` of the submission, from MDF Connect. This value may be `None` or an old ID if the submission failed.\n",
    "    - `error` (string): If the submission failed, the reason for failure. If the submission suceeded, this will be `None` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': None,\n",
       " 'source_id': '_test_smaller_example_dataset_submission_v3-3',\n",
       " 'success': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.submit_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking submission status\n",
    "After submitting a dataset to MDF Connect, you can see the status of the submission's processing with these helpers.\n",
    "\n",
    "- [`check_status`](#check_status)\n",
    "- [`check_all_submissions`](#check_all_submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `check_status`\n",
    "To see the progress your submission is making, use `check_status()`. If you haven't cleared the submission from the client, you can use it without arguments to check the most recent submission status.\n",
    "\n",
    "#### Optional arguments:\n",
    "- `source_id` (string): The `source_id` of the submission you want to check on. If you don't supply a `source_id`, the ID of the last submission you made with the client will be used instead (an error will result if you have not submitted a dataset with the client yet and also don't supply an ID).\n",
    "- `raw` (boolean): When `False`, a nicely-formatted status summary will be printed to standard output. When `True`, the full status result will be returned instead (the full result is not recommended for direct human consumption). The default is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mdfcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a19706cd028b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mdfcc' is not defined"
     ]
    }
   ],
   "source": [
    "mdfcc.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfcc.check_status(\"_test_smaller_example_dataset_submission_v1-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `check_all_submissions`\n",
    "If you want to see the status of all submissions you've made to MDF Connect, use `check_all_submissions()`. This method is helpful if you forget a submission's `source_id`, or you have multiple submissions processing at once.\n",
    "\n",
    "#### Optional arguments:\n",
    "- `verbose` (boolean): When `False`, a basic summary of your submissions will be printed. When `True`, the full status summary of each submission will be printed, in the same form as `check_status()`. The default is `False`. (This argument has no effect if `raw` is `True`.)\n",
    "- `active` (boolean): When `False`, all of your submissions will be shown. When `True`, only submissions that are still active will be shown. The default is `False`.\n",
    "- `raw` (boolean): When `False`, the summary selected by `verbose` will be printed. When `True`, the full status result will be returned instead (the full result is not recommended for direct human consumption). The default is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 404. MDF Connect may be experiencing technical difficulties.\n"
     ]
    }
   ],
   "source": [
    "mdfcc.check_all_submissions(active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfcc.check_all_submissions(verbose=True, active=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
