{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdf_toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "- [Overview/instantiation](#MDF-Connect-Client)\n",
    "- [Mandatory inputs](#Mandatory-inputs)\n",
    "- [Recommended inputs](#Recommended-inputs)\n",
    "- [Optional inputs](#Optional-inputs)\n",
    "- [Submitting a dataset](#Submitting-a-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDF Connect Client\n",
    "The MDF Connect Client (`MDFConnectClient`) is a class designed to help you submit datasets to MDF Connect using Python. It can be automatically created with the `login()` utility (see the Authentication Utilities tutorial).\n",
    "\n",
    "Note: While you can access and modify the internal variables of a client (for example, `mdfcc.data`), it is recommended that you instead only use the helper functions. This tutorial accesses those variables only for display purposes.\n",
    "\n",
    "**IMPORTANT**: To submit data to MDF Connect, you must have an account recognized by Globus Auth (including Google, ORCiD, many academic institutions, or a [free Globus ID](https://www.globusid.org/create)). Additionally, you must be in the [MDF Connect Convert](https://www.globus.org/app/groups/cc192dca-3751-11e8-90c1-0a7c735d220a/about) Globus Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfcc = mdf_toolbox.login(services=[\"mdf_connect\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also instantiate the client directly, and it will attempt to authenticate you automatically. You cannot use MDF Connect anonymously.\n",
    "\n",
    "Additionally, you can set the initial state of the client this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfcc = mdf_toolbox.MDFConnectClient(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_dc_block`\n",
    "The `dc` (DataCite) block is mandatory for all submissions. `create_dc_block()` creates the `dc` block for you.\n",
    "\n",
    "You must provide the `title` and `authors` of your submission. You may also provide the authors' `affiliations` (in the same order as the authors), the `publisher` and `publication_year`, and the `description`, as well as the DOI for the dataset itself as `dataset_doi` and related DOIs (such as a journal article) as `related_dois`.\n",
    "\n",
    "Note about `affiliations`: If the affiliations for each author are different, you must supply each author's affiliation(s) in order. If you supply a different number of affiliations (1 affiliation for 3 authors, for example), all affiliations will apply to all authors. See the extended example below.\n",
    "\n",
    "If you understand the DataCite schema, you can also add other keyword arguments corresponding to DataCite fields.\n",
    "\n",
    "You cannot clear the `dc` block. You can overwrite the `dc` block by calling this method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra affiliations examples\n",
    "authors = [\"Fromnist, Alice\", \"Fromnist; Bob\", \"Cathy Multiples\"]\n",
    "\n",
    "# If all authors are from NIST:\n",
    "affiliations = \"NIST\"\n",
    "\n",
    "# If all authors are from both NIST and UChicago:\n",
    "affiliations = [\"NIST\", \"UChicago\"]\n",
    "\n",
    "# If Alice and Bob are from NIST, Cathy is from NIST and UChicago:\n",
    "affliliations = [\"NIST\", \"NIST\", [\"NIST\", \"UChicago\"]]\n",
    "\n",
    "# This is incorrect! If applying affiliations to all authors, lists must not be nested.\n",
    "# These apply to all authors because there are 4 affiliations for 3 authors.\n",
    "affiliations = [\"NIST\", [\"NIST\", \"UChicago\"], \"Argonne\", \"Oak Ridge\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creators': [{'affiliations': ['The Foo Bar Institute of Data'],\n",
       "   'creatorName': 'Smith, Foo',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Foo'},\n",
       "  {'affiliations': ['The Foo Bar Institute of Data'],\n",
       "   'creatorName': 'Smith, Bar',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Bar'},\n",
       "  {'affiliations': ['The Foo Bar Institute of Data'],\n",
       "   'creatorName': 'Smith, Baz',\n",
       "   'familyName': 'Smith',\n",
       "   'givenName': 'Baz'}],\n",
       " 'publicationYear': '2018',\n",
       " 'publisher': 'The Journal of Foo-Bar Data',\n",
       " 'resourceType': {'resourceType': 'Dataset', 'resourceTypeGeneral': 'Dataset'},\n",
       " 'titles': [{'title': 'Foo, Bar, and Baz in Big Data'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_dc_block(title=\"Foo, Bar, and Baz in Big Data\",\n",
    "                      authors=[\"Foo Smith\", \"Smith, Bar\", \"Smith; Baz\"],\n",
    "                      affiliations=[\"The Foo Bar Institute of Data\"],\n",
    "                      publisher=\"The Journal of Foo-Bar Data\")\n",
    "mdfcc.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `add_data`\n",
    "Some kind of data is mandatory for all submissions. `add_data()` will add a data location to your dataset. This action is cumulative, so each calls adds more data. Subsequent calls do not overwrite.\n",
    "\n",
    "You can add data located at a Globus endpoint, HTTP(S) link, or Google Drive. Connect will extract data located in archives, including zips.\n",
    "\n",
    "- Globus endpoint: `globus://endpoint_id/path/to/data` or you can copy the \"Get link\" link from the Globus Web App. The data must be shared with `mdf_dataset_submission`, which is the MDF Connect Globus account. (This account will show up as `c17f27bb-f200-486a-b785-2a25e82af505@clients.auth.globus.org`.)\n",
    "- HTTP(S): Copy the link exactly. The data must be accessible without authentication.\n",
    "- Google Drive: `googledrive:///path/from/shared/location`. You must share the data with materialsdatafacility@gmail.com.\n",
    "\n",
    "To clear all data from the submission, call `clear_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dl.dropboxusercontent.com/u/12345/abcdef',\n",
       " 'googledrive:///mydata.zip',\n",
       " 'globus://1a2b3c/data/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_data(\"https://dl.dropboxusercontent.com/u/12345/abcdef\")\n",
    "mdfcc.add_data([\"googledrive:///mydata.zip\", \"globus://1a2b3c/data/\"])\n",
    "mdfcc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_data()\n",
    "mdfcc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual test data, using a Globus Web App link\n",
    "mdfcc.add_data(\"https://www.globus.org/app/transfer?origin_id=e38ee745-6d04-11e5-ba46-22000b92c6ec&origin_path=%2Fcitrine_mdf_demo%2Falloy.pbe%2FAlFe%2F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `add_index`\n",
    "To process JSON, CSV, YAML, XML, or Excel files, MDF Connect requires a mapping that translates the file into MDF schema format. `add_index()` allows you to attach a `mapping` to a `data_type`, and specify a `delimiter` for tabular data, as well as the `na_values`, when applicable.\n",
    "\n",
    "Mappings must be dictionaries, where the key is the MDF schema field, expressed in dot notation (see examples below) and the value is the data's field or column.\n",
    "\n",
    "Each data type can only have one associated mapping, so multiple calls with the same data type will overwrite. Calls with different data types will not overwrite. To clear all the mappings, call `clear_index()`.\n",
    "\n",
    "For more information on the MDF schemas, see the official JSONSchema repository at https://github.com/materials-data-facility/data-schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example, assume there is a JSON file in the data that is structured like this:\n",
    "```json\n",
    "{\n",
    "    \"my_data\": {\n",
    "        \"mat\": {\n",
    "            \"comp\": \"H\"\n",
    "        },\n",
    "        \"atom_num\": 1\n",
    "    },\n",
    "    \"space_grp\": 10\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"material.composition\": \"my_data.mat.comp\",\n",
    "    \"crystal_structure.number_of_atoms\": \"my_data.atom_num\",\n",
    "    \"crystal_structure.space_group_number\": \"space_grp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'json': {'mapping': {'crystal_structure.number_of_atoms': 'my_data.atom_num',\n",
       "   'crystal_structure.space_group_number': 'space_grp',\n",
       "   'material.composition': 'my_data.mat.comp'}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_index(\"json\", mapping)\n",
    "mdfcc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_index()\n",
    "mdfcc.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `add_service`\n",
    "MDF Connect has integrations to submit data to other community services, as well as additional MDF-related options. To automatically submit your dataset to an integrated service, use `add_service()`. If the service you're submitting to has additional configuration parameters, use `parameters` to set them. This action is cumulative, so subsequent cals will add more services, not overwrite previous.\n",
    "\n",
    "Integrated services include:\n",
    "\n",
    "- `globus_publish`, the Globus/MDF publication service with DOI minting\n",
    "- `citrine`, industry-partnered machine-learning specialists\n",
    "- `mrr`, the NIST Materials Resource Registry\n",
    "\n",
    "To clear all the service selections from your submission, call `clear_services()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citrine': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_service(\"citrine\")\n",
    "mdfcc.services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_services()\n",
    "mdfcc.services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `set_test`\n",
    "You can use `set_test()` to create a test submission as a dry-run for MDF Connect. The submission will go through the normal processing, but the results will not be submitted to the normal locations. This flag is a great way to tell if your submission will process the way you want it to.\n",
    "\n",
    "- Tests are ingested into the `mdf-test` search index\n",
    "- Tests are submitted to the MDF Test collection in Globus Publish (if `globus_publish` requested)\n",
    "- Tests are not made public on Citrination (if `citrine` requested)\n",
    "- Tests are given a special `source_id` by prepending `_test_`\n",
    "\n",
    "To turn the test flag off, use `test=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_test(False)\n",
    "mdfcc.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_test(True)\n",
    "mdfcc.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `add_repositories`\n",
    "`add_repositories()` adds repository tags to your submission. This action is cumulative, so each call adds more repositories. Subsequent calls do not overwrite.\n",
    "\n",
    "Some repositories may be added automatically if implied by your supplied tags. Repositories that aren't recognized may be discarded.\n",
    "\n",
    "To clear your repository tags, call `clear_repositories()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repositories': ['APS', 'NREL']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.add_repositories([\"APS\", \"NREL\"])\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_repositories()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `set_custom_block`\n",
    "The `__custom` block is an area for you to add your own custom metadata, if it isn't covered by the MDF schema. It can be set by calling `set_custom_block()`. You are allowed ten keys in this dictionary.\n",
    "\n",
    "Note that, unlike the `index` mappings, you supply the actual values for the dataset-level `__custom` block.\n",
    "\n",
    "You can clear the `__custom` block by passing in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quench_method': 'water'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_values = {\n",
    "        \"quench_method\": \"water\"\n",
    "}\n",
    "mdfcc.set_custom_block(custom_values)\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_custom_block({})\n",
    "mdfcc.custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `set_acl`\n",
    "`set_acl()` sets the Access Control List for this submission. It can contain the Globus UUIDs of users and/or groups allowed to access the submission, or `\"public\"` to make the submission open to everyone.\n",
    "\n",
    "You can reset the ACL to the default (public) with `clear_acl()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acl': ['UUID1', 'UUID2']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_acl([\"UUID1\", \"UUID2\"])\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_acl()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `set_source_name`\n",
    "`set_source_name()` sets the `source_name` of your dataset. By default, the `source_name` is generated based on the title of your dataset (as set in the `dc` block). If your title is long or otherwise unwieldy to type or remember, setting a custom `source_name` can help.\n",
    "\n",
    "You can reset the `source_name` to the default by calling `clear_source_name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_name': 'my_foobar_dataset'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.set_source_name(\"my_foobar_dataset\")\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.clear_source_name()\n",
    "mdfcc.mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_mrr_block`\n",
    "`create_mrr_block()` adds data for the NIST Materials Resource Registry into your submission. Currently, you must build a dictionary with the appropriate fields yourself.\n",
    "\n",
    "You can clear the `mrr` block by passing in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataOrigin': 'experiment'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_mrr_block({\"dataOrigin\": \"experiment\"})\n",
    "mdfcc.mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.create_mrr_block({})\n",
    "mdfcc.mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting a dataset\n",
    "After you have created your submission with the above helpers, you can submit and check your submission with the following helpers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_submission`\n",
    "`get_submission()` shows you your current submission, as it will be sent to MDF Connect. This method is a great way to check for any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': ['https://www.globus.org/app/transfer?origin_id=e38ee745-6d04-11e5-ba46-22000b92c6ec&origin_path=%2Fcitrine_mdf_demo%2Falloy.pbe%2FAlFe%2F'],\n",
       " 'dc': {'creators': [{'affiliations': ['The Foo Bar Institute of Data'],\n",
       "    'creatorName': 'Smith, Foo',\n",
       "    'familyName': 'Smith',\n",
       "    'givenName': 'Foo'},\n",
       "   {'affiliations': ['The Foo Bar Institute of Data'],\n",
       "    'creatorName': 'Smith, Bar',\n",
       "    'familyName': 'Smith',\n",
       "    'givenName': 'Bar'},\n",
       "   {'affiliations': ['The Foo Bar Institute of Data'],\n",
       "    'creatorName': 'Smith, Baz',\n",
       "    'familyName': 'Smith',\n",
       "    'givenName': 'Baz'}],\n",
       "  'publicationYear': '2018',\n",
       "  'publisher': 'The Journal of Foo-Bar Data',\n",
       "  'resourceType': {'resourceType': 'Dataset',\n",
       "   'resourceTypeGeneral': 'Dataset'},\n",
       "  'titles': [{'title': 'Foo, Bar, and Baz in Big Data'}]},\n",
       " 'test': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.get_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `reset_submission`\n",
    "If you need to clear away your entire submission, call `reset_submission()`. This is irreversible.\n",
    "\n",
    "Caution: This method will clear the current `source_id`, which means that you will have to keep track of any previous `source_id`s from other submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdfcc.reset_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `submit_dataset`\n",
    "`submit_dataset()` will send your dataset to MDF Connect for indexing. You will get back the `source_id` if the submission is successful. The `source_id` is the unique identifier for your specific submission, and can be used to check the status of your submission later. The `source_id` is also saved to the client.\n",
    "\n",
    "You can set `test=True` here to force a test submission (`test=False` is the default and has no effect). If you need to submit the same dataset again, you can use `resubmit=True` which bypasses the duplicate submission check. If you want to clear your submission after sending it, set `reset=True`.\n",
    "\n",
    "If you have assembled your submission manually (not using the helpers), you can give the dictionary to `submission` and the method will send if for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_test_foo_bar_baz_in_big_data_v4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.submit_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `check_status`\n",
    "To see the progress your submission is making, use `check_status()`. If you haven't cleared the submission from the client, you can use it without arguments to check the most recent submission status. You can also pass in a `source_id` to check the status of a different submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status of TEST convert submission _test_foo_bar_baz_in_big_data_v4 (Foo, Bar, and Baz in Big Data)\n",
      "Submitted by Jonathon Gaff at 2018-07-05T14:22:37.862744Z\n",
      "\n",
      "Conversion initialization was successful.\n",
      "Conversion data download is in progress.\n",
      "Data conversion has not started yet.\n",
      "Ingestion preparation has not started yet.\n",
      "Ingestion initialization has not started yet.\n",
      "Ingestion data download has not started yet.\n",
      "Integration data download has not started yet.\n",
      "Globus Search ingestion has not started yet.\n",
      "Globus Publish publication has not started yet.\n",
      "Citrine upload has not started yet.\n",
      "Materials Resource Registration has not started yet.\n",
      "Post-processing cleanup has not started yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdfcc.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status of TEST convert submission _test_foo_bar_baz_in_big_data_v1 (Foo, Bar, and Baz in Big Data)\n",
      "Submitted by Jonathon Gaff at 2018-06-27T21:14:52.076218Z\n",
      "\n",
      "Conversion initialization was successful.\n",
      "Conversion data download was successful.\n",
      "Data conversion was successful: 7 records parsed out of 7 groups.\n",
      "Ingestion preparation was successful.\n",
      "Ingestion initialization was successful.\n",
      "Ingestion data download was not requested or required.\n",
      "Integration data download was not requested or required.\n",
      "Globus Search ingestion was successful.\n",
      "Globus Publish publication was not requested or required.\n",
      "Citrine upload was not requested or required.\n",
      "Materials Resource Registration was not requested or required.\n",
      "Post-processing cleanup was successful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdfcc.check_status(\"_test_foo_bar_baz_in_big_data_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `raw=True` to get the raw response from MDF Connect.\n",
    "\n",
    "This response is messy and not meant for general human consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_id': '_test_foo_bar_baz_in_big_data_v1',\n",
       " 'status_code': 'SSMSSNNSNNNS',\n",
       " 'status_list': [{'signal': 'success',\n",
       "   'text': 'Conversion initialization was successful.'},\n",
       "  {'signal': 'success', 'text': 'Conversion data download was successful.'},\n",
       "  {'signal': 'success',\n",
       "   'text': 'Data conversion was successful: 7 records parsed out of 7 groups.'},\n",
       "  {'signal': 'success', 'text': 'Ingestion preparation was successful.'},\n",
       "  {'signal': 'success', 'text': 'Ingestion initialization was successful.'},\n",
       "  {'signal': 'idle',\n",
       "   'text': 'Ingestion data download was not requested or required.'},\n",
       "  {'signal': 'idle',\n",
       "   'text': 'Integration data download was not requested or required.'},\n",
       "  {'signal': 'success', 'text': 'Globus Search ingestion was successful.'},\n",
       "  {'signal': 'idle',\n",
       "   'text': 'Globus Publish publication was not requested or required.'},\n",
       "  {'signal': 'idle', 'text': 'Citrine upload was not requested or required.'},\n",
       "  {'signal': 'idle',\n",
       "   'text': 'Materials Resource Registration was not requested or required.'},\n",
       "  {'signal': 'success', 'text': 'Post-processing cleanup was successful.'}],\n",
       " 'status_message': 'Status of TEST convert submission _test_foo_bar_baz_in_big_data_v1 (Foo, Bar, and Baz in Big Data)\\nSubmitted by Jonathon Gaff at 2018-06-27T21:14:52.076218Z\\n\\nConversion initialization was successful.\\nConversion data download was successful.\\nData conversion was successful: 7 records parsed out of 7 groups.\\nIngestion preparation was successful.\\nIngestion initialization was successful.\\nIngestion data download was not requested or required.\\nIntegration data download was not requested or required.\\nGlobus Search ingestion was successful.\\nGlobus Publish publication was not requested or required.\\nCitrine upload was not requested or required.\\nMaterials Resource Registration was not requested or required.\\nPost-processing cleanup was successful.\\n',\n",
       " 'submission_time': '2018-06-27T21:14:52.076218Z',\n",
       " 'submitter': 'Jonathon Gaff',\n",
       " 'test': True,\n",
       " 'title': 'Foo, Bar, and Baz in Big Data'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfcc.check_status(\"_test_foo_bar_baz_in_big_data_v1\", raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
